{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b14289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this two lines only if running the very first time\n",
    "# !pip install python-dotenv\n",
    "# !pip install yfinance --upgrade\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338cbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap sp500 tickers using pandas datareader\n",
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\") # Resource from wikipedia\n",
    "ticker_table = tables[0]\n",
    "tickers = ticker_table['Symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca92c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ticker, start_year, end_year):\n",
    "    \n",
    "    start_year = start_year\n",
    "    end_year = end_year + 1\n",
    "    company_tick = ticker\n",
    "    load_dotenv('.env_2')  # Load environment variables from the file '.env'\n",
    "    API_KEY_FMP = os.environ.get('API_KEY_FMP')  # Retrieve the value of the environment variable 'API_KEY_FMP'\n",
    "    API_KEY_FRED = os.environ.get('API_KEY_FRED')  # Retrieve the value of the environment variable 'API_KEY_FRED'\n",
    "\n",
    "    # Construct API request endpoint url\n",
    "    BASE_URL_FMP = 'https://financialmodelingprep.com/api/v3'\n",
    "    endpoint_url_dividend = f\"{BASE_URL_FMP}/historical-price-full/stock_dividend/{company_tick}?apikey={API_KEY_FMP}\"\n",
    "    endpoint_url_company_rating = f\"{BASE_URL_FMP}/historical-rating/{company_tick}?apikey={API_KEY_FMP}\"\n",
    "    BASE_URL_FRED = 'https://api.stlouisfed.org/fred/series/observations'\n",
    "    endpoint_url_interest_rate = f\"{BASE_URL_FRED}?series_id=FEDFUNDS&api_key={API_KEY_FRED}&file_type=json&frequency=a&aggregation_method=avg&observation_start={start_year - 1}-01-01&observation_end={end_year - 1}-12-31\"\n",
    "    endpoint_url_inflation_rate = f\"{BASE_URL_FRED}?series_id=CPIAUCSL&api_key={API_KEY_FRED}&file_type=json&frequency=a&aggregation_method=avg&observation_start={start_year - 1}-01-01&observation_end={end_year - 1}-12-31\"\n",
    "\n",
    "\n",
    "    # Send an HTTP GET request to the endpoint URL and store the response\n",
    "    response = requests.get(endpoint_url_dividend)\n",
    "    if response.status_code == 429:\n",
    "        print(\"FMP API limit reached\", {endpoint_url_dividend})\n",
    "    elif response.status_code == 400:\n",
    "        print(\"Invalid syntax\", {endpoint_url_dividend})\n",
    "    elif response.status_code == 403:\n",
    "        print(\"Unauthorized access\", {endpoint_url_dividend})\n",
    "    elif response.status_code == 404:\n",
    "        print(\"Can not find requested resources\", {endpoint_url_dividend})\n",
    "    elif response.status_code == 408:\n",
    "        print(\"Request Timeout\", {endpoint_url_dividend})\n",
    "    elif response.status_code == 508:\n",
    "        print(\"Loop Detected\", {endpoint_url_dividend})\n",
    "    elif response.status_code == 511:\n",
    "        print(\"Network Authentication Required\", {endpoint_url_dividend})\n",
    "    import pandas as pd\n",
    "\n",
    "    # Convert json to dictionary object and then a Pandas Dataframe\n",
    "    response_dict = response.json()\n",
    "    dividends = pd.DataFrame(response_dict['historical'])\n",
    "\n",
    "\n",
    "\n",
    "    # Data Transformation\n",
    "    if dividends.shape == (0, 0):  # Handle the case where the company never issued any dividend in the past\n",
    "        dividends = pd.DataFrame({\n",
    "            \"year\": list(range(start_year - 1, end_year + 1)),\n",
    "            \"adjDividend\": [0.0] * len(list(range(start_year - 1, end_year + 1)))  # Obtaining 2 more years' data\n",
    "        })\n",
    "    else:\n",
    "        # Extract year data from the date column\n",
    "        dividends['year'] = pd.to_datetime(dividends['date']).dt.year\n",
    "        # Aggregate the dividend paid by year\n",
    "        dividends = dividends.groupby(\"year\").agg({\"adjDividend\": \"sum\"}).reset_index()\n",
    "        # Create a new DataFrame with all years from start to end - So that we don't omit years without dividends\n",
    "        all_years = pd.DataFrame({'year': list(range(start_year - 1, end_year + 1))})\n",
    "        # Merge the two DataFrames on the year column and fill missing values with 0.0\n",
    "        dividends = all_years.merge(dividends, on='year', how='left').fillna(0.0)\n",
    "\n",
    "\n",
    "    dividends['next_year_dividend'] = dividends['adjDividend'].shift(-1)\n",
    "\n",
    "    conditions = [\n",
    "        dividends['adjDividend'] <= dividends['next_year_dividend'],\n",
    "        dividends['adjDividend'] > dividends['next_year_dividend']\n",
    "    ]\n",
    "    choices = ['constant/increased', 'decreased']\n",
    "\n",
    "    # Create the target column 'dps_change' based on the conditions\n",
    "    dividends['dps_change_next_year'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "    # Construct dps change from last year\n",
    "    dividends['last_year_dividend'] = dividends['adjDividend'].shift(1)\n",
    "    dividends['dps_growth'] = dividends['adjDividend'] - dividends['last_year_dividend']\n",
    "\n",
    "    # Another predictor that we can create is dividend change as a percentage\n",
    "    dividends['dps_growth_rate'] = np.where(\n",
    "        (dividends['last_year_dividend'] == 0) & (dividends['adjDividend'] == 0),\n",
    "        0,  # If both are 0 then change is 0\n",
    "        np.where(\n",
    "            dividends['last_year_dividend'] != 0,\n",
    "            ((dividends['adjDividend'] / dividends['last_year_dividend']) - 1) * 100,\n",
    "            999  # If last year dividend is 0 then return 999\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Remove the first last year since they will be NaN\n",
    "    dividends = dividends.loc[(dividends['year'] >= start_year) & (dividends['year'] <= end_year - 1)]\n",
    "    # Only keep the columns that we need\n",
    "    dividends = dividends[[\"year\", \"adjDividend\", \"dps_growth\", \"dps_growth_rate\", \"dps_change_next_year\"]]\n",
    "\n",
    "\n",
    "    # Engineer some other predictors\n",
    "    predictors = pd.DataFrame({\"year\": list(range(start_year - 1, end_year))})  # Include one more year before\n",
    "                                                                                # the first year to calculate changes\n",
    "\n",
    "    # Include the Company's Industry and sector data\n",
    "    import yfinance as yf\n",
    "    company_data_raw = yf.Ticker(company_tick)\n",
    "    company_data = company_data_raw.info\n",
    "    if 'industry' not in company_data:\n",
    "        predictors['industry'] = 'NA'\n",
    "        print(f\"Company {company_tick} industry information is not available\")\n",
    "    else:\n",
    "        predictors[\"industry\"] = company_data['industry']\n",
    "    if 'sector' not in company_data:\n",
    "        predictors[\"sector\"] = 'NA'\n",
    "        print(f\"Company {company_tick} sector information is not available\")\n",
    "    else:\n",
    "        predictors[\"sector\"] = company_data['sector']\n",
    "\n",
    "\n",
    "    # Company Historical Rating\n",
    "    # Send an HTTP GET request to the endpoint URL and store the response\n",
    "    response = requests.get(endpoint_url_company_rating)\n",
    "    if response.status_code == 429:\n",
    "        print(\"FMP API limit reached\", {endpoint_url_company_rating})\n",
    "    elif response.status_code == 400:\n",
    "        print(\"Invalid syntax\", {endpoint_url_company_rating})\n",
    "    elif response.status_code == 403:\n",
    "        print(\"Unauthorized access\", {endpoint_url_company_rating})\n",
    "    elif response.status_code == 404:\n",
    "        print(\"Can not find requested resources\", {endpoint_url_company_rating})\n",
    "    elif response.status_code == 408:\n",
    "        print(\"Request Timeout\", {endpoint_url_company_rating})\n",
    "    elif response.status_code == 508:\n",
    "        print(\"Loop Detected\", {endpoint_url_company_rating})\n",
    "    elif response.status_code == 511:\n",
    "        print(\"Network Authentication Required\", {endpoint_url_company_rating})\n",
    "\n",
    "    # Convert json to dictionary object and then a Pandas Dataframe\n",
    "    import pandas as pd\n",
    "    response_dict = response.json()\n",
    "    company_rating = pd.DataFrame(response_dict)\n",
    "\n",
    "\n",
    "    # Data Transformation\n",
    "    if company_rating.shape == (0, 0):  # Handle the case where the company has no rating in the past\n",
    "        company_rating = pd.DataFrame({\n",
    "            \"year\": list(range(start_year - 1, end_year + 1)),\n",
    "            \"ratingScore\": [0.0] * len(list(range(start_year - 1, end_year + 1)))  # We are obtaining 2 more years' data\n",
    "        })\n",
    "    else:\n",
    "        # Extract year data from the date column\n",
    "        company_rating['year'] = pd.to_datetime(company_rating['date']).dt.year\n",
    "        # Aggregate the rating by year\n",
    "        company_rating = company_rating.groupby(\"year\").agg({\"ratingScore\": \"mean\"}).reset_index()\n",
    "        # Create a new DataFrame with all years from start to end - So that we don't omit years without rating\n",
    "        all_years = pd.DataFrame({'year': list(range(start_year - 1, end_year + 1))})\n",
    "        # Merge the two DataFrames on the year column and fill missing values with 0.0\n",
    "        company_rating = all_years.merge(company_rating, on='year', how='left').fillna(0.0)\n",
    "        predictors['companyRating'] = company_rating['ratingScore'].astype(\"float64\")\n",
    "\n",
    "\n",
    "\n",
    "    # Let's add some Macroeconomics indicators: the annualized Federal Interest Rate\n",
    "\n",
    "    response = requests.get(endpoint_url_interest_rate)\n",
    "    if response.status_code == 429:\n",
    "        print(\"FRED API limit reached\", {endpoint_url_interest_rate})\n",
    "    elif response.status_code == 400:\n",
    "        print(\"Invalid syntax\", {endpoint_url_interest_rate})\n",
    "    elif response.status_code == 403:\n",
    "        print(\"Unauthorized access\", {endpoint_url_interest_rate})\n",
    "    elif response.status_code == 404:\n",
    "        print(\"Can not find requested resources\", {endpoint_url_interest_rate})\n",
    "    elif response.status_code == 408:\n",
    "        print(\"Request Timeout\", {endpoint_url_interest_rate})\n",
    "    elif response.status_code == 508:\n",
    "        print(\"Loop Detected\", {endpoint_url_interest_rate})\n",
    "    elif response.status_code == 511:\n",
    "        print(\"Network Authentication Required\", {endpoint_url_interest_rate})\n",
    "    data = response.json()\n",
    "\n",
    "    fed_interest_rates = pd.DataFrame(data['observations'])\n",
    "    predictors['interestRate'] = fed_interest_rates['value'].astype(\"float64\")\n",
    "\n",
    "\n",
    "\n",
    "    response = requests.get(endpoint_url_inflation_rate)\n",
    "    if response.status_code == 429:\n",
    "        print(\"FRED API limit reached\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 400:\n",
    "        print(\"Invalid syntax\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 403:\n",
    "        print(\"Unauthorized access\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 404:\n",
    "        print(\"Can not find requested resources\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 408:\n",
    "        print(\"Request Timeout\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 508:\n",
    "        print(\"Loop Detected\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 511:\n",
    "        print(\"Network Authentication Required\", {endpoint_url_inflation_rate})\n",
    "    data = response.json()\n",
    "\n",
    "    # Convert data into DataFrame and convert values to float\n",
    "    cpi_data = pd.DataFrame(data['observations'])\n",
    "    predictors['inflationRate'] = cpi_data['value'].astype(\"float64\")\n",
    "\n",
    "    num_of_years = 2024 - start_year + 1\n",
    "\n",
    "    response = requests.get(f\"{BASE_URL_FMP}/ratios/{company_tick}?limit={num_of_years}&apikey={API_KEY_FMP}\")\n",
    "    if response.status_code == 429:\n",
    "        print(\"FMP API limit reached\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 400:\n",
    "        print(\"Invalid syntax\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 403:\n",
    "        print(\"Unauthorized access\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 404:\n",
    "        print(\"Can not find requested resources\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 408:\n",
    "        print(\"Request Timeout\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 508:\n",
    "        print(\"Loop Detected\", {endpoint_url_inflation_rate})\n",
    "    elif response.status_code == 511:\n",
    "        print(\"Network Authentication Required\", {endpoint_url_inflation_rate})\n",
    "\n",
    "\n",
    "    # Check if all year's data is available\n",
    "    data_length = len(response.json())\n",
    "    if data_length != num_of_years:\n",
    "        print(f\"Company {company_tick} financial data is not available\")\n",
    "        return\n",
    "\n",
    "    financial_ratios = pd.DataFrame(response.json()).iloc[:, :].sort_values(\"date\", ascending=True).reset_index(drop=True)\n",
    "    financial_ratios['calendarYear'] = financial_ratios['calendarYear'].astype('int64')\n",
    "    predictors = predictors.merge(financial_ratios, left_on='year', right_on='calendarYear', how='left').fillna(0.0)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    predictors.drop([\"date\", \"calendarYear\", \"period\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_percentage_change(df, feature_name):\n",
    "        percentage_change = df[feature_name].pct_change() * 100\n",
    "        # Create new column name\n",
    "        new_col_name = f\"{feature_name}_percentage_change\"\n",
    "        # Find the index position of the original predictor column\n",
    "        original_col_position = df.columns.get_loc(feature_name)\n",
    "        # Insert the new column right after the original predictor column\n",
    "        predictors.insert(original_col_position + 1, new_col_name, percentage_change)\n",
    "\n",
    "\n",
    "    def calculate_actual_change(df, feature_name):\n",
    "        actual_change = df[feature_name].diff()\n",
    "        # Create new column name\n",
    "        new_col_name = f\"{feature_name}_actual_change\"\n",
    "        # Find the index position of the original predictor column\n",
    "        original_col_position = df.columns.get_loc(feature_name)\n",
    "        # Insert the new column right after the original predictor column\n",
    "        predictors.insert(original_col_position + 2, new_col_name, actual_change)    \n",
    "\n",
    "    feature_list = list(predictors.columns)\n",
    "\n",
    "    feature_list.remove('year')\n",
    "    feature_list.remove('industry')\n",
    "    feature_list.remove('sector')\n",
    "    feature_list.remove('symbol')\n",
    "\n",
    "\n",
    "\n",
    "    for feature in feature_list:\n",
    "        calculate_percentage_change(predictors, feature)\n",
    "        calculate_actual_change(predictors, feature)\n",
    "\n",
    "\n",
    "\n",
    "    # Replacing inf and NaN values\n",
    "    predictors.replace([float('inf'), float('-inf')], 999, inplace=True)\n",
    "    predictors.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    # Combine dividend data with other predictors\n",
    "    dataset = pd.merge(dividends, predictors, left_on='year', right_on='year', how='left')\n",
    "\n",
    "    # Move target to the end of the dataset for good practice\n",
    "    feature_list = list(dataset.columns)\n",
    "    feature_list.append('dps_change_next_year')\n",
    "    feature_list.remove('dps_change_next_year')\n",
    "    dataset = dataset[feature_list]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db1d5d0a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Obtaining data for MMM\n",
      "2: Obtaining data for AOS\n",
      "3: Obtaining data for ABT\n",
      "4: Obtaining data for ABBV\n",
      "5: Obtaining data for ACN\n",
      "6: Obtaining data for ADBE\n",
      "7: Obtaining data for AMD\n",
      "8: Obtaining data for AES\n",
      "9: Obtaining data for AFL\n",
      "10: Obtaining data for A\n",
      "11: Obtaining data for APD\n",
      "12: Obtaining data for ABNB\n",
      "Company ABNB financial data is not available\n",
      "13: Obtaining data for AKAM\n",
      "14: Obtaining data for ALB\n",
      "15: Obtaining data for ARE\n",
      "16: Obtaining data for ALGN\n",
      "17: Obtaining data for ALLE\n",
      "18: Obtaining data for LNT\n",
      "19: Obtaining data for ALL\n",
      "20: Obtaining data for GOOGL\n",
      "21: Obtaining data for GOOG\n",
      "22: Obtaining data for MO\n",
      "23: Obtaining data for AMZN\n",
      "24: Obtaining data for AMCR\n",
      "25: Obtaining data for AEE\n",
      "26: Obtaining data for AAL\n",
      "27: Obtaining data for AEP\n",
      "28: Obtaining data for AXP\n",
      "29: Obtaining data for AIG\n",
      "30: Obtaining data for AMT\n",
      "31: Obtaining data for AWK\n",
      "32: Obtaining data for AMP\n",
      "33: Obtaining data for AME\n",
      "34: Obtaining data for AMGN\n",
      "35: Obtaining data for APH\n",
      "36: Obtaining data for ADI\n",
      "37: Obtaining data for ANSS\n",
      "38: Obtaining data for AON\n",
      "39: Obtaining data for APA\n",
      "40: Obtaining data for AAPL\n",
      "41: Obtaining data for AMAT\n",
      "42: Obtaining data for APTV\n",
      "43: Obtaining data for ACGL\n",
      "44: Obtaining data for ADM\n",
      "45: Obtaining data for ANET\n",
      "46: Obtaining data for AJG\n",
      "47: Obtaining data for AIZ\n",
      "48: Obtaining data for T\n",
      "49: Obtaining data for ATO\n",
      "50: Obtaining data for ADSK\n",
      "51: Obtaining data for ADP\n",
      "52: Obtaining data for AZO\n",
      "53: Obtaining data for AVB\n",
      "54: Obtaining data for AVY\n",
      "55: Obtaining data for AXON\n",
      "56: Obtaining data for BKR\n",
      "Company BKR financial data is not available\n",
      "57: Obtaining data for BALL\n",
      "58: Obtaining data for BAC\n",
      "59: Obtaining data for BK\n",
      "60: Obtaining data for BBWI\n",
      "61: Obtaining data for BAX\n",
      "62: Obtaining data for BDX\n",
      "63: Obtaining data for BRK.B\n",
      "Company BRK.B industry information is not available\n",
      "Company BRK.B sector information is not available\n",
      "Company BRK.B financial data is not available\n",
      "64: Obtaining data for BBY\n",
      "65: Obtaining data for BIO\n",
      "66: Obtaining data for TECH\n",
      "67: Obtaining data for BIIB\n",
      "68: Obtaining data for BLK\n",
      "69: Obtaining data for BX\n",
      "70: Obtaining data for BA\n",
      "71: Obtaining data for BKNG\n",
      "72: Obtaining data for BWA\n",
      "73: Obtaining data for BXP\n",
      "74: Obtaining data for BSX\n",
      "75: Obtaining data for BMY\n",
      "76: Obtaining data for AVGO\n",
      "77: Obtaining data for BR\n",
      "78: Obtaining data for BRO\n",
      "79: Obtaining data for BF.B\n",
      "Company BF.B industry information is not available\n",
      "Company BF.B sector information is not available\n",
      "Company BF.B financial data is not available\n",
      "80: Obtaining data for BLDR\n",
      "81: Obtaining data for BG\n",
      "82: Obtaining data for CDNS\n",
      "83: Obtaining data for CZR\n",
      "84: Obtaining data for CPT\n",
      "85: Obtaining data for CPB\n",
      "86: Obtaining data for COF\n",
      "87: Obtaining data for CAH\n",
      "88: Obtaining data for KMX\n",
      "89: Obtaining data for CCL\n",
      "90: Obtaining data for CARR\n",
      "Company CARR financial data is not available\n",
      "91: Obtaining data for CTLT\n",
      "92: Obtaining data for CAT\n",
      "93: Obtaining data for CBOE\n",
      "94: Obtaining data for CBRE\n",
      "95: Obtaining data for CDW\n",
      "96: Obtaining data for CE\n",
      "97: Obtaining data for COR\n",
      "98: Obtaining data for CNC\n",
      "99: Obtaining data for CNP\n",
      "100: Obtaining data for CF\n",
      "101: Obtaining data for CHRW\n",
      "102: Obtaining data for CRL\n",
      "103: Obtaining data for SCHW\n",
      "104: Obtaining data for CHTR\n",
      "105: Obtaining data for CVX\n",
      "106: Obtaining data for CMG\n",
      "107: Obtaining data for CB\n",
      "108: Obtaining data for CHD\n",
      "109: Obtaining data for CI\n",
      "110: Obtaining data for CINF\n",
      "111: Obtaining data for CTAS\n",
      "112: Obtaining data for CSCO\n",
      "113: Obtaining data for C\n",
      "114: Obtaining data for CFG\n",
      "115: Obtaining data for CLX\n",
      "116: Obtaining data for CME\n",
      "117: Obtaining data for CMS\n",
      "118: Obtaining data for KO\n",
      "119: Obtaining data for CTSH\n",
      "120: Obtaining data for CL\n",
      "121: Obtaining data for CMCSA\n",
      "122: Obtaining data for CMA\n",
      "123: Obtaining data for CAG\n",
      "124: Obtaining data for COP\n",
      "125: Obtaining data for ED\n",
      "126: Obtaining data for STZ\n",
      "127: Obtaining data for CEG\n",
      "128: Obtaining data for COO\n",
      "129: Obtaining data for CPRT\n",
      "130: Obtaining data for GLW\n",
      "131: Obtaining data for CPAY\n",
      "Company CPAY financial data is not available\n",
      "132: Obtaining data for CTVA\n",
      "Company CTVA financial data is not available\n",
      "133: Obtaining data for CSGP\n",
      "134: Obtaining data for COST\n",
      "135: Obtaining data for CTRA\n",
      "136: Obtaining data for CCI\n",
      "137: Obtaining data for CSX\n",
      "138: Obtaining data for CMI\n",
      "139: Obtaining data for CVS\n",
      "140: Obtaining data for DHR\n",
      "141: Obtaining data for DRI\n",
      "142: Obtaining data for DVA\n",
      "143: Obtaining data for DAY\n",
      "Company DAY financial data is not available\n",
      "144: Obtaining data for DECK\n",
      "145: Obtaining data for DE\n",
      "146: Obtaining data for DAL\n",
      "147: Obtaining data for DVN\n",
      "148: Obtaining data for DXCM\n",
      "149: Obtaining data for FANG\n",
      "150: Obtaining data for DLR\n",
      "151: Obtaining data for DFS\n",
      "152: Obtaining data for DG\n",
      "153: Obtaining data for DLTR\n",
      "154: Obtaining data for D\n",
      "155: Obtaining data for DPZ\n",
      "156: Obtaining data for DOV\n",
      "157: Obtaining data for DOW\n",
      "Company DOW financial data is not available\n",
      "158: Obtaining data for DHI\n",
      "159: Obtaining data for DTE\n",
      "160: Obtaining data for DUK\n",
      "161: Obtaining data for DD\n",
      "162: Obtaining data for EMN\n",
      "163: Obtaining data for ETN\n",
      "164: Obtaining data for EBAY\n",
      "165: Obtaining data for ECL\n",
      "166: Obtaining data for EIX\n",
      "167: Obtaining data for EW\n",
      "168: Obtaining data for EA\n",
      "169: Obtaining data for ELV\n",
      "170: Obtaining data for LLY\n",
      "171: Obtaining data for EMR\n",
      "172: Obtaining data for ENPH\n",
      "173: Obtaining data for ETR\n",
      "174: Obtaining data for EOG\n",
      "175: Obtaining data for EPAM\n",
      "176: Obtaining data for EQT\n",
      "177: Obtaining data for EFX\n",
      "178: Obtaining data for EQIX\n",
      "179: Obtaining data for EQR\n",
      "180: Obtaining data for ESS\n",
      "181: Obtaining data for EL\n",
      "182: Obtaining data for ETSY\n",
      "183: Obtaining data for EG\n",
      "184: Obtaining data for EVRG\n",
      "185: Obtaining data for ES\n",
      "186: Obtaining data for EXC\n",
      "187: Obtaining data for EXPE\n",
      "188: Obtaining data for EXPD\n",
      "189: Obtaining data for EXR\n",
      "190: Obtaining data for XOM\n",
      "191: Obtaining data for FFIV\n",
      "192: Obtaining data for FDS\n",
      "193: Obtaining data for FICO\n",
      "194: Obtaining data for FAST\n",
      "195: Obtaining data for FRT\n",
      "196: Obtaining data for FDX\n",
      "197: Obtaining data for FIS\n",
      "198: Obtaining data for FITB\n",
      "199: Obtaining data for FSLR\n",
      "200: Obtaining data for FE\n",
      "201: Obtaining data for FI\n",
      "202: Obtaining data for FMC\n",
      "203: Obtaining data for F\n",
      "204: Obtaining data for FTNT\n",
      "205: Obtaining data for FTV\n",
      "206: Obtaining data for FOXA\n",
      "Company FOXA financial data is not available\n",
      "207: Obtaining data for FOX\n",
      "Company FOX financial data is not available\n",
      "208: Obtaining data for BEN\n",
      "209: Obtaining data for FCX\n",
      "210: Obtaining data for GRMN\n",
      "211: Obtaining data for IT\n",
      "212: Obtaining data for GE\n",
      "213: Obtaining data for GEHC\n",
      "Company GEHC financial data is not available\n",
      "214: Obtaining data for GEV\n",
      "Company GEV financial data is not available\n",
      "215: Obtaining data for GEN\n",
      "216: Obtaining data for GNRC\n",
      "217: Obtaining data for GD\n",
      "218: Obtaining data for GIS\n",
      "219: Obtaining data for GM\n",
      "220: Obtaining data for GPC\n",
      "221: Obtaining data for GILD\n",
      "222: Obtaining data for GPN\n",
      "223: Obtaining data for GL\n",
      "224: Obtaining data for GS\n",
      "225: Obtaining data for HAL\n",
      "226: Obtaining data for HIG\n",
      "227: Obtaining data for HAS\n",
      "228: Obtaining data for HCA\n",
      "229: Obtaining data for DOC\n",
      "230: Obtaining data for HSIC\n",
      "231: Obtaining data for HSY\n",
      "232: Obtaining data for HES\n",
      "233: Obtaining data for HPE\n",
      "234: Obtaining data for HLT\n",
      "235: Obtaining data for HOLX\n",
      "236: Obtaining data for HD\n",
      "237: Obtaining data for HON\n",
      "238: Obtaining data for HRL\n",
      "239: Obtaining data for HST\n",
      "240: Obtaining data for HWM\n",
      "241: Obtaining data for HPQ\n",
      "242: Obtaining data for HUBB\n",
      "243: Obtaining data for HUM\n",
      "244: Obtaining data for HBAN\n",
      "245: Obtaining data for HII\n",
      "246: Obtaining data for IBM\n",
      "247: Obtaining data for IEX\n",
      "248: Obtaining data for IDXX\n",
      "249: Obtaining data for ITW\n",
      "250: Obtaining data for ILMN\n",
      "251: Obtaining data for INCY\n",
      "252: Obtaining data for IR\n",
      "Company IR financial data is not available\n",
      "253: Obtaining data for PODD\n",
      "254: Obtaining data for INTC\n",
      "255: Obtaining data for ICE\n",
      "256: Obtaining data for IFF\n",
      "257: Obtaining data for IP\n",
      "258: Obtaining data for IPG\n",
      "259: Obtaining data for INTU\n",
      "260: Obtaining data for ISRG\n",
      "261: Obtaining data for IVZ\n",
      "262: Obtaining data for INVH\n",
      "Company INVH financial data is not available\n",
      "263: Obtaining data for IQV\n",
      "264: Obtaining data for IRM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265: Obtaining data for JBHT\n",
      "266: Obtaining data for JBL\n",
      "267: Obtaining data for JKHY\n",
      "268: Obtaining data for J\n",
      "269: Obtaining data for JNJ\n",
      "270: Obtaining data for JCI\n",
      "271: Obtaining data for JPM\n",
      "272: Obtaining data for JNPR\n",
      "273: Obtaining data for K\n",
      "274: Obtaining data for KVUE\n",
      "Company KVUE financial data is not available\n",
      "275: Obtaining data for KDP\n",
      "276: Obtaining data for KEY\n",
      "277: Obtaining data for KEYS\n",
      "278: Obtaining data for KMB\n",
      "279: Obtaining data for KIM\n",
      "280: Obtaining data for KMI\n",
      "281: Obtaining data for KLAC\n",
      "282: Obtaining data for KHC\n",
      "283: Obtaining data for KR\n",
      "284: Obtaining data for LHX\n",
      "285: Obtaining data for LH\n",
      "286: Obtaining data for LRCX\n",
      "287: Obtaining data for LW\n",
      "Company LW financial data is not available\n",
      "288: Obtaining data for LVS\n",
      "289: Obtaining data for LDOS\n",
      "290: Obtaining data for LEN\n",
      "291: Obtaining data for LIN\n",
      "292: Obtaining data for LYV\n",
      "293: Obtaining data for LKQ\n",
      "294: Obtaining data for LMT\n",
      "295: Obtaining data for L\n",
      "296: Obtaining data for LOW\n",
      "297: Obtaining data for LULU\n",
      "298: Obtaining data for LYB\n",
      "299: Obtaining data for MTB\n",
      "300: Obtaining data for MRO\n",
      "301: Obtaining data for MPC\n",
      "302: Obtaining data for MKTX\n",
      "303: Obtaining data for MAR\n",
      "304: Obtaining data for MMC\n",
      "305: Obtaining data for MLM\n",
      "306: Obtaining data for MAS\n",
      "307: Obtaining data for MA\n",
      "308: Obtaining data for MTCH\n",
      "309: Obtaining data for MKC\n",
      "310: Obtaining data for MCD\n",
      "311: Obtaining data for MCK\n",
      "312: Obtaining data for MDT\n",
      "313: Obtaining data for MRK\n",
      "314: Obtaining data for META\n",
      "315: Obtaining data for MET\n",
      "316: Obtaining data for MTD\n",
      "317: Obtaining data for MGM\n",
      "318: Obtaining data for MCHP\n",
      "319: Obtaining data for MU\n",
      "320: Obtaining data for MSFT\n",
      "321: Obtaining data for MAA\n",
      "322: Obtaining data for MRNA\n",
      "Company MRNA financial data is not available\n",
      "323: Obtaining data for MHK\n",
      "324: Obtaining data for MOH\n",
      "325: Obtaining data for TAP\n",
      "326: Obtaining data for MDLZ\n",
      "327: Obtaining data for MPWR\n",
      "328: Obtaining data for MNST\n",
      "329: Obtaining data for MCO\n",
      "330: Obtaining data for MS\n",
      "331: Obtaining data for MOS\n",
      "332: Obtaining data for MSI\n",
      "333: Obtaining data for MSCI\n",
      "334: Obtaining data for NDAQ\n",
      "335: Obtaining data for NTAP\n",
      "336: Obtaining data for NFLX\n",
      "337: Obtaining data for NEM\n",
      "338: Obtaining data for NWSA\n",
      "339: Obtaining data for NWS\n",
      "340: Obtaining data for NEE\n",
      "341: Obtaining data for NKE\n",
      "342: Obtaining data for NI\n",
      "343: Obtaining data for NDSN\n",
      "344: Obtaining data for NSC\n",
      "345: Obtaining data for NTRS\n",
      "346: Obtaining data for NOC\n",
      "347: Obtaining data for NCLH\n",
      "348: Obtaining data for NRG\n",
      "349: Obtaining data for NUE\n",
      "350: Obtaining data for NVDA\n",
      "351: Obtaining data for NVR\n",
      "352: Obtaining data for NXPI\n",
      "353: Obtaining data for ORLY\n",
      "354: Obtaining data for OXY\n",
      "355: Obtaining data for ODFL\n",
      "356: Obtaining data for OMC\n",
      "357: Obtaining data for ON\n",
      "358: Obtaining data for OKE\n",
      "359: Obtaining data for ORCL\n",
      "360: Obtaining data for OTIS\n",
      "Company OTIS financial data is not available\n",
      "361: Obtaining data for PCAR\n",
      "362: Obtaining data for PKG\n",
      "363: Obtaining data for PANW\n",
      "364: Obtaining data for PARA\n",
      "365: Obtaining data for PH\n",
      "366: Obtaining data for PAYX\n",
      "367: Obtaining data for PAYC\n",
      "368: Obtaining data for PYPL\n",
      "369: Obtaining data for PNR\n",
      "370: Obtaining data for PEP\n",
      "371: Obtaining data for PFE\n",
      "372: Obtaining data for PCG\n",
      "373: Obtaining data for PM\n",
      "374: Obtaining data for PSX\n",
      "375: Obtaining data for PNW\n",
      "376: Obtaining data for PXD\n",
      "377: Obtaining data for PNC\n",
      "378: Obtaining data for POOL\n",
      "379: Obtaining data for PPG\n",
      "380: Obtaining data for PPL\n",
      "381: Obtaining data for PFG\n",
      "382: Obtaining data for PG\n",
      "383: Obtaining data for PGR\n",
      "384: Obtaining data for PLD\n",
      "385: Obtaining data for PRU\n",
      "386: Obtaining data for PEG\n",
      "387: Obtaining data for PTC\n",
      "388: Obtaining data for PSA\n",
      "389: Obtaining data for PHM\n",
      "390: Obtaining data for QRVO\n",
      "391: Obtaining data for PWR\n",
      "392: Obtaining data for QCOM\n",
      "393: Obtaining data for DGX\n",
      "394: Obtaining data for RL\n",
      "395: Obtaining data for RJF\n",
      "396: Obtaining data for RTX\n",
      "397: Obtaining data for O\n",
      "398: Obtaining data for REG\n",
      "399: Obtaining data for REGN\n",
      "400: Obtaining data for RF\n",
      "401: Obtaining data for RSG\n",
      "402: Obtaining data for RMD\n",
      "403: Obtaining data for RVTY\n",
      "404: Obtaining data for RHI\n",
      "405: Obtaining data for ROK\n",
      "406: Obtaining data for ROL\n",
      "407: Obtaining data for ROP\n",
      "408: Obtaining data for ROST\n",
      "409: Obtaining data for RCL\n",
      "410: Obtaining data for SPGI\n",
      "411: Obtaining data for CRM\n",
      "412: Obtaining data for SBAC\n",
      "413: Obtaining data for SLB\n",
      "414: Obtaining data for STX\n",
      "415: Obtaining data for SRE\n",
      "416: Obtaining data for NOW\n",
      "417: Obtaining data for SHW\n",
      "418: Obtaining data for SPG\n",
      "419: Obtaining data for SWKS\n",
      "420: Obtaining data for SJM\n",
      "421: Obtaining data for SNA\n",
      "422: Obtaining data for SOLV\n",
      "Company SOLV financial data is not available\n",
      "423: Obtaining data for SO\n",
      "424: Obtaining data for LUV\n",
      "425: Obtaining data for SWK\n",
      "426: Obtaining data for SBUX\n",
      "427: Obtaining data for STT\n",
      "428: Obtaining data for STLD\n",
      "429: Obtaining data for STE\n",
      "430: Obtaining data for SYK\n",
      "431: Obtaining data for SMCI\n",
      "432: Obtaining data for SYF\n",
      "433: Obtaining data for SNPS\n",
      "434: Obtaining data for SYY\n",
      "435: Obtaining data for TMUS\n",
      "436: Obtaining data for TROW\n",
      "437: Obtaining data for TTWO\n",
      "438: Obtaining data for TPR\n",
      "439: Obtaining data for TRGP\n",
      "440: Obtaining data for TGT\n",
      "441: Obtaining data for TEL\n",
      "442: Obtaining data for TDY\n",
      "443: Obtaining data for TFX\n",
      "444: Obtaining data for TER\n",
      "445: Obtaining data for TSLA\n",
      "446: Obtaining data for TXN\n",
      "447: Obtaining data for TXT\n",
      "448: Obtaining data for TMO\n",
      "449: Obtaining data for TJX\n",
      "450: Obtaining data for TSCO\n",
      "451: Obtaining data for TT\n",
      "452: Obtaining data for TDG\n",
      "453: Obtaining data for TRV\n",
      "454: Obtaining data for TRMB\n",
      "455: Obtaining data for TFC\n",
      "456: Obtaining data for TYL\n",
      "457: Obtaining data for TSN\n",
      "458: Obtaining data for USB\n",
      "459: Obtaining data for UBER\n",
      "Company UBER financial data is not available\n",
      "460: Obtaining data for UDR\n",
      "461: Obtaining data for ULTA\n",
      "462: Obtaining data for UNP\n",
      "463: Obtaining data for UAL\n",
      "464: Obtaining data for UPS\n",
      "465: Obtaining data for URI\n",
      "466: Obtaining data for UNH\n",
      "467: Obtaining data for UHS\n",
      "468: Obtaining data for VLO\n",
      "469: Obtaining data for VTR\n",
      "470: Obtaining data for VLTO\n",
      "Company VLTO financial data is not available\n",
      "471: Obtaining data for VRSN\n",
      "472: Obtaining data for VRSK\n",
      "473: Obtaining data for VZ\n",
      "474: Obtaining data for VRTX\n",
      "475: Obtaining data for VTRS\n",
      "476: Obtaining data for VICI\n",
      "Company VICI financial data is not available\n",
      "477: Obtaining data for V\n",
      "478: Obtaining data for VMC\n",
      "479: Obtaining data for WRB\n",
      "480: Obtaining data for WAB\n",
      "481: Obtaining data for WBA\n",
      "482: Obtaining data for WMT\n",
      "483: Obtaining data for DIS\n",
      "484: Obtaining data for WBD\n",
      "485: Obtaining data for WM\n",
      "486: Obtaining data for WAT\n",
      "487: Obtaining data for WEC\n",
      "488: Obtaining data for WFC\n",
      "489: Obtaining data for WELL\n",
      "490: Obtaining data for WST\n",
      "491: Obtaining data for WDC\n",
      "492: Obtaining data for WRK\n",
      "493: Obtaining data for WY\n",
      "494: Obtaining data for WMB\n",
      "495: Obtaining data for WTW\n",
      "496: Obtaining data for GWW\n",
      "497: Obtaining data for WYNN\n",
      "498: Obtaining data for XEL\n",
      "499: Obtaining data for XYL\n",
      "500: Obtaining data for YUM\n",
      "501: Obtaining data for ZBRA\n",
      "502: Obtaining data for ZBH\n",
      "503: Obtaining data for ZTS\n"
     ]
    }
   ],
   "source": [
    "start_year = 2013\n",
    "end_year = 2022\n",
    "\n",
    "\n",
    "dataset = []\n",
    "company_number = 1\n",
    "for ticker in tickers:\n",
    "    print(f\"{company_number}: Obtaining data for {ticker}\")\n",
    "    company_number = company_number + 1\n",
    "    company_data = get_data(ticker, start_year, end_year)\n",
    "    if type(company_data).__name__ == \"int\":\n",
    "        continue\n",
    "    dataset.append(company_data)\n",
    "dataset = pd.concat(dataset, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b9e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to disk\n",
    "dataset.to_csv(\"Stock_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee52529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c2801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.540\n",
       "1       3.420\n",
       "2       4.100\n",
       "3       4.440\n",
       "4       4.700\n",
       "        ...  \n",
       "4795    0.504\n",
       "4796    0.656\n",
       "4797    0.800\n",
       "4798    1.000\n",
       "4799    1.300\n",
       "Name: adjDividend, Length: 4800, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['adjDividend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b90ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
